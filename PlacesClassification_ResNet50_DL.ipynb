{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports for building a deep learning model using PyTorch, Torchvision, and other essential libraries.\n",
    "\n",
    "- PyTorch: Provides deep learning functionality, including neural networks, optimization, and custom datasets.\n",
    "- Torchvision: Contains utilities for vision-based tasks, including datasets and image transformations.\n",
    "- Image handling and visualization: Libraries for handling and displaying images, including OpenCV.\n",
    "- Data manipulation: Libraries for handling data, file processing, and randomization.\n",
    "\"\"\"\n",
    "\n",
    "# PyTorch core imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset  # Dataset for custom dataset creation\n",
    "\n",
    "# Torchvision imports for vision-based tasks\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "# Image handling and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2  # OpenCV for image processing\n",
    "\n",
    "# Data manipulation and file handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter  # Counting utility for analyzing data\n",
    "import glob  # File path handling\n",
    "import os  # Operating system interface for directory management\n",
    "\n",
    "# Randomization\n",
    "from random import shuffle, seed  # Random shuffling and seeding for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Free unused memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "TRAIN_DIR = './data/data_256'\n",
    "TEST_DIR = './data/test_256'\n",
    "VAL_DIR = './data/val_256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_dir(directory):\n",
    "    '''\n",
    "    Counts the number of files in each subdirectory of the given directory,\n",
    "    returning a DataFrame with folder names, subfolder names, and their image counts.\n",
    "\n",
    "    Type 'quit' to exit, or 'default' to display all folders.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the main directory containing subfolders.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): DataFrame containing folder names, subfolder names, and image counts.\n",
    "    '''\n",
    "    data = []\n",
    "\n",
    "    # Iterate through subdirectories (folders)\n",
    "    for folder in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "\n",
    "        # Check if it's a directory (i.e., a folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Iterate through subdirectories (subfolders)\n",
    "            for subdir in os.listdir(folder_path):\n",
    "                subdir_path = os.path.join(folder_path, subdir)\n",
    "\n",
    "                # Check if it's a directory (i.e., a subfolder)\n",
    "                if os.path.isdir(subdir_path):\n",
    "                    # Count number of files in the subdirectory\n",
    "                    file_count = len(os.listdir(subdir_path))\n",
    "                    data.append({'Folder': folder, 'Subfolder': subdir, 'Image Count': file_count})\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    user_input = input(\"Enter your choice: \").strip().lower()\n",
    "\n",
    "    if user_input == 'quit':\n",
    "        print(\"Exiting the program.\")\n",
    "        return None  # or you can raise an exception or return a specific value if needed\n",
    "    elif user_input == 'default':\n",
    "        pd.set_option('display.max_rows', None)  # Show all rows in DataFrame\n",
    "        return df\n",
    "    elif user_input.isalpha() and len(user_input) == 1:\n",
    "        # Display the selected folder's subfolders\n",
    "        filtered_df = df[df['Folder'].str.lower() == user_input]  # Filter by folder\n",
    "        if not filtered_df.empty:\n",
    "            pd.set_option('display.max_rows', None)  # Show all rows in DataFrame\n",
    "            return filtered_df\n",
    "        else:\n",
    "            print(f\"No subfolders found for folder: {user_input}\")\n",
    "            return None  # or handle this case as needed\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter a valid folder letter or 'quit'.\")\n",
    "        return None  # or handle this case as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count files in train and test directories\n",
    "train_class_counts = count_files_in_dir(TRAIN_DIR)\n",
    "train_class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c01faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "    TODO: docstring\n",
    "    '''\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        \n",
    "        # Load all images from the directory\n",
    "        for filename in os.listdir(root_dir):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg')):  # Adjust extensions as needed\n",
    "                self.images.append(os.path.join(root_dir, filename))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Ensure image is in RGB format\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "def load_preprocess_resnet50(train_dir=TRAIN_DIR, val_dir=VAL_DIR, test_dir=TEST_DIR, batch_size=32):\n",
    "    '''\n",
    "    Load and preprocess the data for ResNet50 by iterating through directories\n",
    "    a-z in the train_dir and applying ImageFolder to each one. Also loads \n",
    "    validation and test data.\n",
    "\n",
    "    Args:\n",
    "        train_dir (str): Path to the training data directory.\n",
    "        val_dir (str): Path to the validation data directory.\n",
    "        test_dir (str): Path to the test data directory.\n",
    "        batch_size (int): The batch size for the DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        tuple: DataLoader for training, validation, and test datasets, and list of class names.\n",
    "    '''\n",
    "\n",
    "    # Define the transformations for ResNet50\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "    ])\n",
    "\n",
    "    def create_dataset_from_folders(parent_dir):\n",
    "        \"\"\"\n",
    "        Iterates through directories (a-z) at the same level in parent_dir \n",
    "        and applies ImageFolder to each directory.\n",
    "        \"\"\"\n",
    "        datasets_list = []\n",
    "        class_names = set()  # Use a set to avoid duplicates\n",
    "        for folder in os.listdir(parent_dir):  # Loop through folders a-z\n",
    "            folder_path = os.path.join(parent_dir, folder)\n",
    "\n",
    "            if os.path.isdir(folder_path):\n",
    "                # Apply ImageFolder on each folder (a, b, c, etc.)\n",
    "                folder_dataset = datasets.ImageFolder(root=folder_path, transform=transform)\n",
    "                datasets_list.append(folder_dataset)\n",
    "                # Collect class names from this folder's dataset\n",
    "                class_names.update(folder_dataset.classes)\n",
    "\n",
    "        return ConcatDataset(datasets_list), sorted(list(class_names))  # Concatenate all folder datasets and return class names\n",
    "\n",
    "    # Create the training dataset and get the unique class names\n",
    "    train_dataset, class_names = create_dataset_from_folders(train_dir)\n",
    "\n",
    "    # Create DataLoader for the training dataset\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create DataLoader for the validation dataset using CustomDataset\n",
    "    val_dataset = CustomDataset(root_dir=val_dir, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Create DataLoader for the test dataset using CustomDataset\n",
    "    test_dataset = CustomDataset(root_dir=test_dir, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50_CNN(nn.Module):\n",
    "    '''\n",
    "    Custom ResNet50 model for image classification with the option to add custom layers.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_classes, custom_layers=None):\n",
    "        super(ResNet50_CNN, self).__init__()\n",
    "        \n",
    "        # Load the pre-trained ResNet50 model\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Remove the last fully connected layer\n",
    "        self.resnet50.fc = nn.Identity()  # Use Identity layer to keep the output from the last block\n",
    "\n",
    "        # Custom layers can be added if specified\n",
    "        self.custom_layers = custom_layers if custom_layers is not None else nn.Identity()  # Identity if no custom layers\n",
    "\n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(2048, num_classes)  # Input features are now 2048\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet50(x)  # Forward pass through ResNet50\n",
    "        x = self.custom_layers(x)  # Forward pass through custom layers (if any)\n",
    "        x = self.fc(x)  # Final classification layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba98507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def train_val_cnn(num_epochs=5, learning_rate=0.001):\n",
    "   pass\n",
    "\n",
    "# Call the training function\n",
    "train_val_cnn()\n",
    "\n",
    "# TODO: SOTA METHOD"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
