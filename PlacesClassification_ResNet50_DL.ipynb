{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports for building a deep learning model using PyTorch, Torchvision, and other essential libraries.\n",
    "\n",
    "- PyTorch: Provides deep learning functionality, including neural networks, optimization, and custom datasets.\n",
    "- Torchvision: Contains utilities for vision-based tasks, including datasets and image transformations.\n",
    "- Image handling and visualization: Libraries for handling and displaying images, including OpenCV.\n",
    "- Data manipulation: Libraries for handling data, file processing, and randomization.\n",
    "\"\"\"\n",
    "\n",
    "# PyTorch core imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, SubsetRandomSampler  # Dataset for custom dataset creation\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# CUDA\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Torchvision imports for vision-based tasks\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "# Image handling and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2  # OpenCV for image processing\n",
    "from tqdm import tqdm # For progress bars \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Data manipulation and file handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter  # Counting utility for analyzing data\n",
    "import glob  # File path handling\n",
    "import os  # Operating system interface for directory management\n",
    "\n",
    "# Randomization\n",
    "from random import shuffle, seed  # Random shuffling and seeding for reproducibility\n",
    "\n",
    "# Optimization\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57bd1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b03e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Free unused memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f50715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "TRAIN_DIR = './data/data_256'\n",
    "TEST_DIR = './data/test_256'\n",
    "VAL_DIR = './data/val_256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac6172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_dir(directory):\n",
    "    '''\n",
    "    Counts the number of files in each subdirectory of the given directory,\n",
    "    returning a DataFrame with folder names, subfolder names, and their image counts.\n",
    "\n",
    "    Type 'quit' to exit, or 'default' to display all folders.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the main directory containing subfolders.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): DataFrame containing folder names, subfolder names, and image counts.\n",
    "    '''\n",
    "    data = []\n",
    "\n",
    "    # Iterate through subdirectories (folders)\n",
    "    for folder in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "\n",
    "        # Check if it's a directory (i.e., a folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Iterate through subdirectories (subfolders)\n",
    "            for subdir in os.listdir(folder_path):\n",
    "                subdir_path = os.path.join(folder_path, subdir)\n",
    "\n",
    "                # Check if it's a directory (i.e., a subfolder)\n",
    "                if os.path.isdir(subdir_path):\n",
    "                    # Count number of files in the subdirectory\n",
    "                    file_count = len(os.listdir(subdir_path))\n",
    "                    data.append({'Folder': folder, 'Subfolder': subdir, 'Image Count': file_count})\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    user_input = input(\"Enter your choice: \").strip().lower()\n",
    "\n",
    "    if user_input == 'quit':\n",
    "        print(\"Exiting the program.\")\n",
    "        return None  # or you can raise an exception or return a specific value if needed\n",
    "    elif user_input == 'default':\n",
    "        pd.set_option('display.max_rows', None)  # Show all rows in DataFrame\n",
    "        return df\n",
    "    elif user_input.isalpha() and len(user_input) == 1:\n",
    "        # Display the selected folder's subfolders\n",
    "        filtered_df = df[df['Folder'].str.lower() == user_input]  # Filter by folder\n",
    "        if not filtered_df.empty:\n",
    "            pd.set_option('display.max_rows', None)  # Show all rows in DataFrame\n",
    "            return filtered_df\n",
    "        else:\n",
    "            print(f\"No subfolders found for folder: {user_input}\")\n",
    "            return None  # or handle this case as needed\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter a valid folder letter or 'quit'.\")\n",
    "        return None  # or handle this case as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e2635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "# Count files in train and test directories\n",
    "train_class_counts = count_files_in_dir(TRAIN_DIR)\n",
    "train_class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c01faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, labeled=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.labeled = labeled\n",
    "        \n",
    "        # Load all images and labels if available\n",
    "        for root, _, filenames in os.walk(root_dir):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(root, filename)\n",
    "                    self.images.append(img_path)\n",
    "                    if labeled:\n",
    "                        # Assuming label is the parent directory name\n",
    "                        label = os.path.basename(os.path.dirname(img_path))\n",
    "                        self.labels.append(label)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.labeled:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.images)\n",
    "\n",
    "def load_preprocess_resnet18(train_dir=TRAIN_DIR, val_dir=VAL_DIR, test_dir=TEST_DIR, batch_size=64):\n",
    "    '''\n",
    "    Load and preprocess the data for ResNet50 by iterating through directories\n",
    "    a-z in the train_dir and applying ImageFolder to each one. Also loads \n",
    "    validation and test data.\n",
    "\n",
    "    Args:\n",
    "        train_dir (str): Path to the training data directory.\n",
    "        val_dir (str): Path to the validation data directory.\n",
    "        test_dir (str): Path to the test data directory.\n",
    "        batch_size (int): The batch size for the DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        tuple: DataLoader for training, validation, and test datasets, and list of class names.\n",
    "    '''\n",
    "\n",
    "    # Define the transformations for ResNet50\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "    ])\n",
    "\n",
    "    def create_dataset_from_folders(parent_dir):\n",
    "        \"\"\"\n",
    "        Iterates through directories (a-z) at the same level in parent_dir \n",
    "        and applies ImageFolder to each directory.\n",
    "        \"\"\"\n",
    "        datasets_list = []\n",
    "        class_names = set()  # Use a set to avoid duplicates\n",
    "        for folder in os.listdir(parent_dir):  # Loop through folders a-z\n",
    "            folder_path = os.path.join(parent_dir, folder)\n",
    "\n",
    "            if os.path.isdir(folder_path):\n",
    "                # Apply ImageFolder on each folder (a, b, c, etc.)\n",
    "                folder_dataset = datasets.ImageFolder(root=folder_path, transform=transform)\n",
    "                datasets_list.append(folder_dataset)\n",
    "                # Collect class names from this folder's dataset\n",
    "                class_names.update(folder_dataset.classes)\n",
    "\n",
    "        return ConcatDataset(datasets_list), sorted(list(class_names))  # Concatenate all folder datasets and return class names\n",
    "\n",
    "    # Create the training dataset and get the unique class names\n",
    "    train_dataset, class_names = create_dataset_from_folders(train_dir)\n",
    "\n",
    "    # Create DataLoader for the training dataset\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create DataLoader for the validation dataset using CustomDataset\n",
    "    val_dataset = CustomDataset(root_dir=val_dir, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Create DataLoader for the test dataset using CustomDataset\n",
    "    test_dataset = CustomDataset(root_dir=test_dir, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6496c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names: ['airfield', 'airplane_cabin', 'airport_terminal', 'alcove', 'alley', 'amphitheater', 'amusement_arcade', 'amusement_park', 'apartment_building', 'aquarium', 'aqueduct', 'arcade', 'arch', 'archaelogical_excavation', 'archive', 'arena', 'army_base', 'art_gallery', 'art_school', 'art_studio', 'artists_loft', 'assembly_line', 'athletic_field', 'atrium', 'attic', 'auditorium', 'auto_factory', 'auto_showroom', 'badlands', 'bakery', 'balcony', 'ball_pit', 'ballroom', 'bamboo_forest', 'bank_vault', 'banquet_hall', 'bar', 'barn', 'barndoor', 'baseball_field', 'basement', 'basketball_court', 'bathroom', 'bazaar', 'beach', 'beach_house', 'beauty_salon', 'bedchamber', 'bedroom', 'beer_garden', 'beer_hall', 'berth', 'biology_laboratory', 'boardwalk', 'boat_deck', 'boathouse', 'bookstore', 'booth', 'botanical_garden', 'bow_window', 'bowling_alley', 'boxing_ring', 'bridge', 'building_facade', 'bullring', 'burial_chamber', 'bus_interior', 'bus_station', 'butchers_shop', 'butte', 'cabin', 'cafeteria', 'campsite', 'campus', 'canal', 'candy_store', 'canyon', 'car_interior', 'carrousel', 'castle', 'catacomb', 'cemetery', 'chalet', 'chemistry_lab', 'childs_room', 'church', 'classroom', 'clean_room', 'cliff', 'closet', 'clothing_store', 'coast', 'cockpit', 'coffee_shop', 'computer_room', 'conference_center', 'conference_room', 'construction_site', 'corn_field', 'corral', 'corridor', 'cottage', 'courthouse', 'courtyard', 'creek', 'crevasse', 'crosswalk', 'dam', 'delicatessen', 'department_store', 'desert', 'desert_road', 'diner', 'dining_hall', 'dining_room', 'discotheque', 'doorway', 'dorm_room', 'downtown', 'dressing_room', 'driveway', 'drugstore', 'elevator', 'elevator_lobby', 'elevator_shaft', 'embassy', 'engine_room', 'entrance_hall', 'escalator', 'excavation', 'fabric_store', 'farm', 'fastfood_restaurant', 'field', 'field_road', 'fire_escape', 'fire_station', 'fishpond', 'flea_market', 'florist_shop', 'food_court', 'football_field', 'forest', 'forest_path', 'forest_road', 'formal_garden', 'fountain', 'galley', 'garage', 'gas_station', 'gazebo', 'general_store', 'gift_shop', 'glacier', 'golf_course', 'greenhouse', 'grotto', 'gymnasium', 'hangar', 'harbor', 'hardware_store', 'hayfield', 'heliport', 'highway', 'home_office', 'home_theater', 'hospital', 'hospital_room', 'hot_spring', 'hotel', 'hotel_room', 'house', 'hunting_lodge', 'ice_cream_parlor', 'ice_floe', 'ice_shelf', 'ice_skating_rink', 'iceberg', 'igloo', 'industrial_area', 'inn', 'islet', 'jacuzzi', 'jail_cell', 'japanese_garden', 'jewelry_shop', 'junkyard', 'kasbah', 'kennel', 'kindergarden_classroom', 'kitchen', 'lagoon', 'lake', 'landfill', 'landing_deck', 'laundromat', 'lawn', 'lecture_room', 'legislative_chamber', 'library', 'lighthouse', 'living_room', 'loading_dock', 'lobby', 'lock_chamber', 'locker_room', 'mansion', 'manufactured_home', 'market', 'marsh', 'martial_arts_gym', 'mausoleum', 'medina', 'mezzanine', 'moat', 'mosque', 'motel', 'mountain', 'mountain_path', 'mountain_snowy', 'movie_theater', 'museum', 'music_studio', 'natural_history_museum', 'nursery', 'nursing_home', 'oast_house', 'ocean', 'office', 'office_building', 'office_cubicles', 'oilrig', 'operating_room', 'orchard', 'orchestra_pit', 'pagoda', 'palace', 'pantry', 'park', 'parking_garage', 'parking_lot', 'pasture', 'patio', 'pavilion', 'pet_shop', 'pharmacy', 'phone_booth', 'physics_laboratory', 'picnic_area', 'pier', 'pizzeria', 'playground', 'playroom', 'plaza', 'pond', 'porch', 'promenade', 'pub', 'racecourse', 'raceway', 'raft', 'railroad_track', 'rainforest', 'reception', 'recreation_room', 'repair_shop', 'residential_neighborhood', 'restaurant', 'restaurant_kitchen', 'restaurant_patio', 'rice_paddy', 'river', 'rock_arch', 'roof_garden', 'rope_bridge', 'ruin', 'runway', 'sandbox', 'sauna', 'schoolhouse', 'science_museum', 'server_room', 'shed', 'shoe_shop', 'shopfront', 'shopping_mall', 'shower', 'ski_resort', 'ski_slope', 'sky', 'skyscraper', 'slum', 'snowfield', 'soccer_field', 'stable', 'stadium', 'stage', 'staircase', 'storage_room', 'street', 'subway_station', 'supermarket', 'sushi_bar', 'swamp', 'swimming_hole', 'swimming_pool', 'synagogue', 'television_room', 'television_studio', 'temple', 'throne_room', 'ticket_booth', 'topiary_garden', 'tower', 'toyshop', 'train_interior', 'train_station', 'tree_farm', 'tree_house', 'trench', 'tundra', 'underwater', 'utility_room', 'valley', 'vegetable_garden', 'veterinarians_office', 'viaduct', 'village', 'vineyard', 'volcano', 'volleyball_court', 'waiting_room', 'water_park', 'water_tower', 'waterfall', 'watering_hole', 'wave', 'wet_bar', 'wheat_field', 'wind_farm', 'windmill', 'yard', 'youth_hostel', 'zen_garden']\n",
      "\n",
      "Train Loader:\n",
      "Batch 1:\n",
      "Images shape: torch.Size([64, 3, 224, 224])\n",
      "Labels: tensor([ 0,  4, 12,  2, 13,  3, 22, 16, 37,  2, 16,  5, 25,  1,  1,  2, 12,  7,\n",
      "         4, 22,  0,  2, 12,  2, 18, 20,  3,  7,  3,  9, 16, 15,  1,  6, 18, 37,\n",
      "        16,  1,  9, 10,  6,  1,  6,  1,  4, 12,  4, 21, 28, 12,  1,  5, 15, 21,\n",
      "         2,  3, 13, 27, 25, 34,  6, 20, 13, 41])\n",
      "\n",
      "Validation Loader:\n",
      "Batch 1:\n",
      "Images shape: torch.Size([64, 3, 224, 224])\n",
      "Labels: None\n",
      "\n",
      "Test Loader:\n",
      "Batch 1:\n",
      "Images shape: torch.Size([64, 3, 224, 224])\n",
      "Labels: None\n"
     ]
    }
   ],
   "source": [
    "def print_loader_samples(loader, loader_name, num_batches=1):\n",
    "    print(f\"\\n{loader_name}:\")\n",
    "    for i, data in enumerate(loader):\n",
    "        print(f\"Batch {i+1}:\")\n",
    "        if isinstance(data, tuple) or isinstance(data, list):\n",
    "            images, labels = data\n",
    "            print(f\"Images shape: {images.shape}\")\n",
    "            print(f\"Labels: {labels}\")\n",
    "        else:\n",
    "            images = data\n",
    "            print(f\"Images shape: {images.shape}\")\n",
    "            print(\"Labels: None\")\n",
    "        if i+1 == num_batches:\n",
    "            break\n",
    "\n",
    "# Assuming you have already loaded your data loaders\n",
    "train_loader, val_loader, test_loader, class_names = load_preprocess_resnet18()\n",
    "\n",
    "# Print the class names\n",
    "print(\"Class Names:\", class_names)\n",
    "\n",
    "# Print samples from each loader\n",
    "print_loader_samples(train_loader, \"Train Loader\", num_batches=1)\n",
    "print_loader_samples(val_loader, \"Validation Loader\", num_batches=1)\n",
    "print_loader_samples(test_loader, \"Test Loader\", num_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4958a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=343, no=128, kernel_size=1, freeze_resnet=True):\n",
    "        super(ResNet18_CNN, self).__init__()\n",
    "        \n",
    "        # Load the pre-trained ResNet18 model with default weights\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        if freeze_resnet:\n",
    "            # Freeze all ResNet18 layers\n",
    "            for param in self.resnet18.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze the last block (layer4) for fine-tuning\n",
    "        for param in self.resnet18.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Remove the original fully connected layer and the average pool\n",
    "        self.features = nn.Sequential(*list(self.resnet18.children())[:-2])  # Output: [batch, 512, 7, 7]\n",
    "        \n",
    "        # Add custom convolutional layer\n",
    "        self.conv = nn.Conv2d(in_channels=512, out_channels=no, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Add Dropout for regularization\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Add global average pooling and a fully connected layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(no, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)          # [batch, 512, 7, 7]\n",
    "        x = self.conv(x)              # [batch, no, 7, 7]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)           # Apply Dropout\n",
    "        x = self.avgpool(x)           # [batch, no, 1, 1]\n",
    "        x = torch.flatten(x, 1)       # [batch, no]\n",
    "        x = self.fc(x)                # [batch, num_classes]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba98507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Class Names: ['airfield', 'airplane_cabin', 'airport_terminal', 'alcove', 'alley', 'amphitheater', 'amusement_arcade', 'amusement_park', 'apartment_building', 'aquarium', 'aqueduct', 'arcade', 'arch', 'archaelogical_excavation', 'archive', 'arena', 'army_base', 'art_gallery', 'art_school', 'art_studio', 'artists_loft', 'assembly_line', 'athletic_field', 'atrium', 'attic', 'auditorium', 'auto_factory', 'auto_showroom', 'badlands', 'bakery', 'balcony', 'ball_pit', 'ballroom', 'bamboo_forest', 'bank_vault', 'banquet_hall', 'bar', 'barn', 'barndoor', 'baseball_field', 'basement', 'basketball_court', 'bathroom', 'bazaar', 'beach', 'beach_house', 'beauty_salon', 'bedchamber', 'bedroom', 'beer_garden', 'beer_hall', 'berth', 'biology_laboratory', 'boardwalk', 'boat_deck', 'boathouse', 'bookstore', 'booth', 'botanical_garden', 'bow_window', 'bowling_alley', 'boxing_ring', 'bridge', 'building_facade', 'bullring', 'burial_chamber', 'bus_interior', 'bus_station', 'butchers_shop', 'butte', 'cabin', 'cafeteria', 'campsite', 'campus', 'canal', 'candy_store', 'canyon', 'car_interior', 'carrousel', 'castle', 'catacomb', 'cemetery', 'chalet', 'chemistry_lab', 'childs_room', 'church', 'classroom', 'clean_room', 'cliff', 'closet', 'clothing_store', 'coast', 'cockpit', 'coffee_shop', 'computer_room', 'conference_center', 'conference_room', 'construction_site', 'corn_field', 'corral', 'corridor', 'cottage', 'courthouse', 'courtyard', 'creek', 'crevasse', 'crosswalk', 'dam', 'delicatessen', 'department_store', 'desert', 'desert_road', 'diner', 'dining_hall', 'dining_room', 'discotheque', 'doorway', 'dorm_room', 'downtown', 'dressing_room', 'driveway', 'drugstore', 'elevator', 'elevator_lobby', 'elevator_shaft', 'embassy', 'engine_room', 'entrance_hall', 'escalator', 'excavation', 'fabric_store', 'farm', 'fastfood_restaurant', 'field', 'field_road', 'fire_escape', 'fire_station', 'fishpond', 'flea_market', 'florist_shop', 'food_court', 'football_field', 'forest', 'forest_path', 'forest_road', 'formal_garden', 'fountain', 'galley', 'garage', 'gas_station', 'gazebo', 'general_store', 'gift_shop', 'glacier', 'golf_course', 'greenhouse', 'grotto', 'gymnasium', 'hangar', 'harbor', 'hardware_store', 'hayfield', 'heliport', 'highway', 'home_office', 'home_theater', 'hospital', 'hospital_room', 'hot_spring', 'hotel', 'hotel_room', 'house', 'hunting_lodge', 'ice_cream_parlor', 'ice_floe', 'ice_shelf', 'ice_skating_rink', 'iceberg', 'igloo', 'industrial_area', 'inn', 'islet', 'jacuzzi', 'jail_cell', 'japanese_garden', 'jewelry_shop', 'junkyard', 'kasbah', 'kennel', 'kindergarden_classroom', 'kitchen', 'lagoon', 'lake', 'landfill', 'landing_deck', 'laundromat', 'lawn', 'lecture_room', 'legislative_chamber', 'library', 'lighthouse', 'living_room', 'loading_dock', 'lobby', 'lock_chamber', 'locker_room', 'mansion', 'manufactured_home', 'market', 'marsh', 'martial_arts_gym', 'mausoleum', 'medina', 'mezzanine', 'moat', 'mosque', 'motel', 'mountain', 'mountain_path', 'mountain_snowy', 'movie_theater', 'museum', 'music_studio', 'natural_history_museum', 'nursery', 'nursing_home', 'oast_house', 'ocean', 'office', 'office_building', 'office_cubicles', 'oilrig', 'operating_room', 'orchard', 'orchestra_pit', 'pagoda', 'palace', 'pantry', 'park', 'parking_garage', 'parking_lot', 'pasture', 'patio', 'pavilion', 'pet_shop', 'pharmacy', 'phone_booth', 'physics_laboratory', 'picnic_area', 'pier', 'pizzeria', 'playground', 'playroom', 'plaza', 'pond', 'porch', 'promenade', 'pub', 'racecourse', 'raceway', 'raft', 'railroad_track', 'rainforest', 'reception', 'recreation_room', 'repair_shop', 'residential_neighborhood', 'restaurant', 'restaurant_kitchen', 'restaurant_patio', 'rice_paddy', 'river', 'rock_arch', 'roof_garden', 'rope_bridge', 'ruin', 'runway', 'sandbox', 'sauna', 'schoolhouse', 'science_museum', 'server_room', 'shed', 'shoe_shop', 'shopfront', 'shopping_mall', 'shower', 'ski_resort', 'ski_slope', 'sky', 'skyscraper', 'slum', 'snowfield', 'soccer_field', 'stable', 'stadium', 'stage', 'staircase', 'storage_room', 'street', 'subway_station', 'supermarket', 'sushi_bar', 'swamp', 'swimming_hole', 'swimming_pool', 'synagogue', 'television_room', 'television_studio', 'temple', 'throne_room', 'ticket_booth', 'topiary_garden', 'tower', 'toyshop', 'train_interior', 'train_station', 'tree_farm', 'tree_house', 'trench', 'tundra', 'underwater', 'utility_room', 'valley', 'vegetable_garden', 'veterinarians_office', 'viaduct', 'village', 'vineyard', 'volcano', 'volleyball_court', 'waiting_room', 'water_park', 'water_tower', 'waterfall', 'watering_hole', 'wave', 'wet_bar', 'wheat_field', 'wind_farm', 'windmill', 'yard', 'youth_hostel', 'zen_garden']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashh\\Downloads\\CV_Places365\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1159: UserWarning: expandable_segments not supported on this platform (Triggered internally at ..\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n",
      "c:\\Users\\yashh\\Downloads\\CV_Places365\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Epoch 1/20 - Training: 100%|██████████| 1000/1000 [03:16<00:00,  5.09it/s, acc=25.01%, loss=2.6211]\n",
      "Epoch 1/20 - Validation:   0%|          | 0/286 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 170\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass Names:\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_names)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# Train and validate the model with limited batches per epoch\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_val_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batches_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Define criterion for testing\u001b[39;00m\n\u001b[0;32m    173\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "Cell \u001b[1;32mIn[10], line 70\u001b[0m, in \u001b[0;36mtrain_val_cnn\u001b[1;34m(num_epochs, learning_rate, patience, max_batches_per_epoch)\u001b[0m\n\u001b[0;32m     68\u001b[0m num_val_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_loader)\n\u001b[0;32m     69\u001b[0m val_progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(val_loader), total\u001b[38;5;241m=\u001b[39mnum_val_batches, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Validation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m val_progress_bar:\n\u001b[0;32m     71\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     72\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def train_val_cnn(num_epochs=20, learning_rate=0.001, patience=5, max_batches_per_epoch=1000):\n",
    "    model = ResNet18_CNN()\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    writer = SummaryWriter('runs/resnet18_experiment')\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    num_train_samples = len(train_loader.dataset)\n",
    "    subset_size = max_batches_per_epoch * train_loader.batch_size  # e.g., 1000 * 128 = 128,000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Generate a random subset of indices for this epoch\n",
    "        indices = np.random.choice(num_train_samples, subset_size, replace=False)\n",
    "        sampler = SubsetRandomSampler(indices)\n",
    "        train_subset_loader = DataLoader(train_loader.dataset, batch_size=train_loader.batch_size, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "\n",
    "        progress_bar = tqdm(enumerate(train_subset_loader), total=max_batches_per_epoch, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")\n",
    "\n",
    "        for batch_idx, (inputs, targets) in progress_bar:\n",
    "            if batch_idx >= max_batches_per_epoch:\n",
    "                break  # This condition is redundant here but kept for safety\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            avg_accuracy = 100 * correct / total\n",
    "\n",
    "            progress_bar.set_postfix(loss=f\"{avg_loss:.4f}\", acc=f\"{avg_accuracy:.2f}%\")\n",
    "\n",
    "        avg_train_loss = running_loss / max_batches_per_epoch\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            num_val_batches = len(val_loader)\n",
    "            val_progress_bar = tqdm(enumerate(val_loader), total=num_val_batches, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\")\n",
    "            for batch_idx, (inputs, targets) in val_progress_bar:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, targets)\n",
    "\n",
    "                running_val_loss += val_loss.item()\n",
    "                _, val_predicted = torch.max(outputs.data, 1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (val_predicted == targets).sum().item()\n",
    "\n",
    "                avg_val_loss = running_val_loss / (batch_idx + 1)\n",
    "                avg_val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "                val_progress_bar.set_postfix(val_loss=f\"{avg_val_loss:.4f}\", val_acc=f\"{avg_val_accuracy:.2f}%\")\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Check for improvement\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save(best_model_state, 'best_model.pth')  # Save the best model\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Train Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {avg_val_loss:.4f}, '\n",
    "              f'Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs.')\n",
    "            break\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Training complete. Best Validation Accuracy: {:.2f}%\".format(best_val_accuracy))\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    return model\n",
    "\n",
    "def test_model(model, test_loader, criterion, device, class_names):\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_test_batches = len(test_loader)\n",
    "        test_progress_bar = tqdm(enumerate(test_loader), total=num_test_batches, desc=\"Testing\")\n",
    "        for batch_idx, (inputs, targets) in test_progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss = criterion(outputs, targets)\n",
    "\n",
    "            running_test_loss += test_loss.item()\n",
    "            _, test_predicted = torch.max(outputs.data, 1)\n",
    "            test_total += targets.size(0)\n",
    "            test_correct += (test_predicted == targets).sum().item()\n",
    "            all_preds.extend(test_predicted.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "            avg_test_loss = running_test_loss / (batch_idx + 1)\n",
    "            avg_test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "            test_progress_bar.set_postfix(test_loss=f\"{avg_test_loss:.4f}\", test_acc=f\"{avg_test_accuracy:.2f}%\")\n",
    "\n",
    "    avg_test_loss = running_test_loss / len(test_loader)\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load data loaders with batch_size=128\n",
    "train_loader, val_loader, test_loader, class_names = load_preprocess_resnet18(batch_size=128)\n",
    "\n",
    "# Print the class names\n",
    "print(\"Class Names:\", class_names)\n",
    "\n",
    "# Train and validate the model with limited batches per epoch\n",
    "trained_model = train_val_cnn(num_epochs=20, learning_rate=0.001, patience=5, max_batches_per_epoch=1000)\n",
    "\n",
    "# Define criterion for testing\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "test_model(trained_model, test_loader, criterion, device, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
